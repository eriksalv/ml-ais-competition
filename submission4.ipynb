{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from geopy.distance import geodesic as geopy_geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_geodetic_distance(y_true_lat, y_true_long, y_pred_lat, y_pred_long):\n",
    "    distances = [\n",
    "        geopy_geodesic((true_lat, true_long), (pred_lat, pred_long)).km\n",
    "        for true_lat, true_long, pred_lat, pred_long in zip(\n",
    "            y_true_lat, y_true_long, y_pred_lat, y_pred_long\n",
    "        )\n",
    "    ]\n",
    "    return np.mean(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cog</th>\n",
       "      <th>sog</th>\n",
       "      <th>rot</th>\n",
       "      <th>heading</th>\n",
       "      <th>navstat</th>\n",
       "      <th>etaRaw</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vesselId</th>\n",
       "      <th>portId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1522060</th>\n",
       "      <td>2024-05-07 23:59:07</td>\n",
       "      <td>359.1</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>05-08 05:00</td>\n",
       "      <td>52.19131</td>\n",
       "      <td>-5.82223</td>\n",
       "      <td>clh6aqawa0002gh0zypfa5dut</td>\n",
       "      <td>634c4de270937fc01c3a7417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522061</th>\n",
       "      <td>2024-05-07 23:59:08</td>\n",
       "      <td>12.3</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>05-10 03:00</td>\n",
       "      <td>38.96142</td>\n",
       "      <td>-12.00502</td>\n",
       "      <td>61e9f3aeb937134a3c4bfe43</td>\n",
       "      <td>634c4de270937fc01c3a76a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522062</th>\n",
       "      <td>2024-05-07 23:59:08</td>\n",
       "      <td>269.8</td>\n",
       "      <td>14.9</td>\n",
       "      <td>-1</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "      <td>05-15 23:00</td>\n",
       "      <td>49.71372</td>\n",
       "      <td>-5.22042</td>\n",
       "      <td>61e9f43db937134a3c4c0169</td>\n",
       "      <td>634c4de270937fc01c3a787b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522063</th>\n",
       "      <td>2024-05-07 23:59:08</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>05-08 12:45</td>\n",
       "      <td>38.27895</td>\n",
       "      <td>10.78280</td>\n",
       "      <td>61e9f469b937134a3c4c029b</td>\n",
       "      <td>61d3781293c6feb83e5eb73b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522064</th>\n",
       "      <td>2024-05-07 23:59:08</td>\n",
       "      <td>336.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>5</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "      <td>05-07 23:00</td>\n",
       "      <td>38.98635</td>\n",
       "      <td>-75.13275</td>\n",
       "      <td>62080cff66fc0a8e43c6123a</td>\n",
       "      <td>61d38528b7b7526e1adf3e6f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time    cog   sog  rot  heading  navstat       etaRaw  \\\n",
       "1522060 2024-05-07 23:59:07  359.1  13.4    0        1        0  05-08 05:00   \n",
       "1522061 2024-05-07 23:59:08   12.3  17.1    0       13        0  05-10 03:00   \n",
       "1522062 2024-05-07 23:59:08  269.8  14.9   -1      270        0  05-15 23:00   \n",
       "1522063 2024-05-07 23:59:08    8.0  18.7    0        6        0  05-08 12:45   \n",
       "1522064 2024-05-07 23:59:08  336.0  14.3    5      337        0  05-07 23:00   \n",
       "\n",
       "         latitude  longitude                   vesselId  \\\n",
       "1522060  52.19131   -5.82223  clh6aqawa0002gh0zypfa5dut   \n",
       "1522061  38.96142  -12.00502   61e9f3aeb937134a3c4bfe43   \n",
       "1522062  49.71372   -5.22042   61e9f43db937134a3c4c0169   \n",
       "1522063  38.27895   10.78280   61e9f469b937134a3c4c029b   \n",
       "1522064  38.98635  -75.13275   62080cff66fc0a8e43c6123a   \n",
       "\n",
       "                           portId  \n",
       "1522060  634c4de270937fc01c3a7417  \n",
       "1522061  634c4de270937fc01c3a76a1  \n",
       "1522062  634c4de270937fc01c3a787b  \n",
       "1522063  61d3781293c6feb83e5eb73b  \n",
       "1522064  61d38528b7b7526e1adf3e6f  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/ais_train.csv\", sep=\"|\")\n",
    "train_df[\"time\"] = pd.to_datetime(train_df[\"time\"])\n",
    "test_df = pd.read_csv(\"data/ais_test.csv\")\n",
    "test_df[\"time\"] = pd.to_datetime(test_df[\"time\"])\n",
    "\n",
    "ports_df = pd.read_csv(\"data/ports.csv\", sep=\"|\")\n",
    "schedules_df = pd.read_csv(\"data/schedules_to_may_2024.csv\", sep=\"|\")\n",
    "vessels_df = pd.read_csv(\"data/vessels.csv\", sep=\"|\")\n",
    "# train_df[\"etaRaw\"] = pd.to_datetime(train_df[\"etaRaw\"], format=\"%Y/%m/%d %H:%M\")\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start = \"2024-05-08 00:00:00\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop vessels with very few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[\n",
    "    ~train_df[\"vesselId\"].isin([\"61e9f3adb937134a3c4bfe37\", \"61e9f3cbb937134a3c4bff09\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove duplicated vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_vessel = \"clh6aqawa0001gh0zmijpuho1\"\n",
    "duplicated_from = \"63d27587e3fba838ce820405\"\n",
    "train_df = train_df[train_df[\"vesselId\"] != duplicated_vessel]\n",
    "# test_df.loc[test_df[\"vesselId\"] == duplicated_vessel, \"vesselId\"] = duplicated_from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set default/missing values to nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df[\"cog\"] >= 360, \"cog\"] = np.nan\n",
    "train_df.loc[train_df[\"sog\"] >= 102.3, \"sog\"] = np.nan\n",
    "train_df.loc[abs(train_df[\"rot\"]) >= 128, \"rot\"] = np.nan\n",
    "train_df.loc[train_df[\"heading\"] > 360, \"heading\"] = np.nan\n",
    "train_df.loc[train_df[\"navstat\"] >= 9, \"navstat\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate vessel stats and cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics for each vessel\n",
    "vessel_stats = (\n",
    "    train_df.groupby(\"vesselId\")\n",
    "    .agg(\n",
    "        mean_latitude=(\"latitude\", \"mean\"),\n",
    "        mean_longitude=(\"longitude\", \"mean\"),\n",
    "        mean_speed=(\"sog\", \"mean\"),\n",
    "        median_speed=(\"sog\", \"median\"),\n",
    "        std_speed=(\"sog\", \"std\"),\n",
    "        count_entries=(\"vesselId\", \"size\"),\n",
    "        pct_navstat_0=(\"navstat\", lambda x: ((x == 0) | (x == 8)).mean() * 100),\n",
    "        pct_navstat_1=(\"navstat\", lambda x: (x == 1).mean() * 100),\n",
    "        pct_navstat_5=(\"navstat\", lambda x: (x == 5).mean() * 100),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "vessel_stats_cols = [col for col in vessel_stats.columns.to_list() if col != \"vesselId\"]\n",
    "vessels_df = vessels_df.merge(vessel_stats, on=\"vesselId\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform KMeans clustering on train_df\n",
    "kmeans = KMeans(n_clusters=20, random_state=42)\n",
    "kmeans.fit(train_df[[\"latitude\", \"longitude\"]])\n",
    "train_df[\"cluster\"] = kmeans.predict(train_df[[\"latitude\", \"longitude\"]])\n",
    "\n",
    "# Encode the cluster each row belongs to with cluster center\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "train_df[\"cluster_center_latitude\"] = train_df[\"cluster\"].apply(\n",
    "    lambda x: cluster_centers[x][0]\n",
    ")\n",
    "train_df[\"cluster_center_longitude\"] = train_df[\"cluster\"].apply(\n",
    "    lambda x: cluster_centers[x][1]\n",
    ")\n",
    "\n",
    "cluster_cols = [\n",
    "    \"cluster\",\n",
    "    \"cluster_center_latitude\",\n",
    "    \"cluster_center_longitude\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stack train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"scaling_factor\"] = np.nan\n",
    "train_df[\"ID\"] = -1\n",
    "full_df = pd.concat([train_df, test_df]).sort_values([\"vesselId\", \"time\"]).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_gdf(\n",
    "    df: pd.DataFrame, longitude_col=\"longitude\", latitude_col=\"latitude\"\n",
    ") -> gpd.GeoDataFrame:\n",
    "    return gpd.GeoDataFrame(\n",
    "        df,\n",
    "        geometry=gpd.points_from_xy(df[longitude_col], df[latitude_col]),\n",
    "        crs=\"EPSG:4326\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"time_diff\"] = full_df.groupby(\"vesselId\")[\"time\"].diff().astype(int) // 10**9\n",
    "\n",
    "# Assume time diff before first msg was 20 min\n",
    "full_df.loc[full_df[\"time_diff\"] < 0, \"time_diff\"] = 60 * 20\n",
    "\n",
    "# full_df = full_df[full_df[\"time_diff\"] >= 60].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = full_df[\"ID\"] == -1\n",
    "full_df.loc[train_mask, \"etaRaw\"] = pd.to_datetime(\n",
    "    \"2024-\" + full_df.loc[train_mask, \"etaRaw\"], errors=\"coerce\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add prev positions, distance, fwd_azimuth, computed sog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Geod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[[\"prev_lat\", \"prev_lng\"]] = full_df.groupby(\"vesselId\")[\n",
    "    [\"latitude\", \"longitude\"]\n",
    "].shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodesic = Geod(ellps=\"WGS84\")\n",
    "fwd_azimuth, back_azimuth, distance = geodesic.inv(\n",
    "    full_df[\"prev_lng\"],\n",
    "    full_df[\"prev_lat\"],\n",
    "    full_df[\"longitude\"],\n",
    "    full_df[\"latitude\"],\n",
    ")\n",
    "\n",
    "full_df[\"distance\"] = distance / (1000 * 1.852)\n",
    "full_df[\"fwd_azimuth\"] = fwd_azimuth\n",
    "full_df[\"prev_distance\"] = full_df[\"distance\"].shift()\n",
    "full_df[\"prev_fwd_azimuth\"] = full_df[\"fwd_azimuth\"].shift()\n",
    "\n",
    "full_df[\"dx\"] = full_df.groupby(\"vesselId\")[\"longitude\"].diff()\n",
    "full_df[\"dy\"] = full_df.groupby(\"vesselId\")[\"latitude\"].diff()\n",
    "\n",
    "# lng, lat, back_azimuth = geodesic.fwd(\n",
    "#     train_df[\"prev_lng\"], train_df[\"prev_lat\"], fwd_azimuth, distance\n",
    "# )\n",
    "# train_df[\"lng_test\"] = lng\n",
    "# train_df[\"lat_test\"] = lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"computed_sog\"] = full_df[\"distance\"] / (full_df[\"time_diff\"] / 3600)\n",
    "full_df[\"prev_sog\"] = full_df[\"computed_sog\"].shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_limit = 50\n",
    "\n",
    "full_df = full_df[(full_df[\"computed_sog\"] < speed_limit) | (full_df[\"ID\"] != -1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge vessels df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.merge(\n",
    "    vessels_df[\n",
    "        [\n",
    "            \"shippingLineId\",\n",
    "            \"vesselId\",\n",
    "            \"CEU\",\n",
    "            \"DWT\",\n",
    "            \"GT\",\n",
    "            \"vesselType\",\n",
    "            \"breadth\",\n",
    "            \"length\",\n",
    "            \"yearBuilt\",\n",
    "        ]\n",
    "        + vessel_stats_cols\n",
    "    ],\n",
    "    on=\"vesselId\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge ports df (calculate distance to closest port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_ports = pd.read_csv(\"data/ports.csv\", sep=\"|\").rename(\n",
    "    {\n",
    "        \"portId\": \"closest_port\",\n",
    "        \"latitude\": \"latitude_port\",\n",
    "        \"longitude\": \"longitude_port\",\n",
    "    },\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_cols = full_df.columns.to_list()\n",
    "distance_col = \"dist_to_port\"\n",
    "\n",
    "ports_gdf = df_to_gdf(\n",
    "    closest_ports, longitude_col=\"longitude_port\", latitude_col=\"latitude_port\"\n",
    ").to_crs(epsg=\"3857\")\n",
    "\n",
    "full_gdf = df_to_gdf(full_df, longitude_col=\"prev_lng\", latitude_col=\"prev_lat\").to_crs(\n",
    "    epsg=\"3857\"\n",
    ")\n",
    "full_gdf = full_gdf.sjoin_nearest(ports_gdf, how=\"left\", distance_col=distance_col)\n",
    "full_df[[distance_col, \"prev_closest_port\", \"latitude_port\", \"longitude_port\"]] = (\n",
    "    full_gdf[[distance_col, \"closest_port\", \"latitude_port\", \"longitude_port\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance to land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_world = gpd.read_file(\"data/land_and_ocean/ne_10m_land.zip\")\n",
    "land_world = land_world.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_cols = full_df.columns.to_list()\n",
    "# df_gdf = df_to_gdf(full_df).to_crs(epsg=\"3857\")\n",
    "\n",
    "# df_with_land = df_gdf.sjoin_nearest(\n",
    "#     land_world, how=\"left\", distance_col=\"distance_to_land\"\n",
    "# )\n",
    "\n",
    "# df = pd.DataFrame(df_with_land)[orig_cols + [\"distance_to_land\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add temporal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_temporal_cols_discrete(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"minute\"] = df[\"time\"].dt.minute\n",
    "    df[\"hour\"] = df[\"time\"].dt.hour\n",
    "    df[\"day_of_week\"] = df[\"time\"].dt.dayofweek\n",
    "    df[\"day_of_month\"] = df[\"time\"].dt.day\n",
    "    df[\"month\"] = df[\"time\"].dt.month\n",
    "    df[\"day_of_year\"] = df[\"time\"].dt.dayofyear\n",
    "    df[\"week_of_year\"] = df[\"time\"].dt.isocalendar().week\n",
    "    cols = [\n",
    "        \"hour\",\n",
    "        \"day_of_week\",\n",
    "        \"day_of_month\",\n",
    "        \"month\",\n",
    "        \"day_of_year\",\n",
    "        \"week_of_year\",\n",
    "    ]\n",
    "    return df, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_temporal_cols_continuous(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    day_s = 24 * 60 * 60\n",
    "    year_s = (366) * day_s\n",
    "    month_s = year_s // 12\n",
    "    timestamp_s = (df[\"time\"] - pd.Timestamp(\"2024-01-01\")) // pd.Timedelta(\"1s\")\n",
    "\n",
    "    df[\"time_day_sin\"] = np.sin(timestamp_s * (2 * np.pi / day_s))\n",
    "    df[\"time_day_cos\"] = np.cos(timestamp_s * (2 * np.pi / day_s))\n",
    "    df[\"time_year_sin\"] = np.sin(timestamp_s * (2 * np.pi / year_s))\n",
    "    df[\"time_year_cos\"] = np.cos(timestamp_s * (2 * np.pi / year_s))\n",
    "    df[\"time_month_sin\"] = np.sin(timestamp_s * (2 * np.pi / month_s))\n",
    "    df[\"time_month_cos\"] = np.cos(timestamp_s * (2 * np.pi / month_s))\n",
    "    cols = [\n",
    "        f\"time_day_sin\",\n",
    "        f\"time_day_cos\",\n",
    "        f\"time_year_sin\",\n",
    "        f\"time_year_cos\",\n",
    "        f\"time_month_sin\",\n",
    "        f\"time_month_cos\",\n",
    "    ]\n",
    "    return df, cols\n",
    "\n",
    "\n",
    "full_df, time_cols = add_temporal_cols_discrete(full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.count import CountEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts of ports might be useful for estimating the size / popularity of the port\n",
    "count_ports_encoder = CountEncoder(handle_missing=\"value\", handle_unknown=-1)\n",
    "count_ports_encoder.fit(\n",
    "    full_df.loc[\n",
    "        ~full_df[\"prev_closest_port\"].isna(),\n",
    "        \"prev_closest_port\",\n",
    "    ].values\n",
    ")\n",
    "full_df.loc[~full_df[\"prev_closest_port\"].isna(), \"closest_port_count\"] = (\n",
    "    count_ports_encoder.transform(\n",
    "        full_df.loc[~full_df[\"prev_closest_port\"].isna(), \"prev_closest_port\"].values\n",
    "    ).values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipping_line_encoder = CountEncoder()\n",
    "shipping_line_encoder.fit(full_df[\"shippingLineId\"].values)\n",
    "full_df[\"shipping_line_count\"] = shipping_line_encoder.transform(\n",
    "    full_df[\"shippingLineId\"].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_cols = [\n",
    "    \"vesselType_83.0\",\n",
    "    \"vesselType_21.0\",\n",
    "    \"vesselType_14.0\",\n",
    "]\n",
    "\n",
    "one_hot = OneHotEncoder(cols=[\"vesselType\"], handle_missing=\"value\", use_cat_names=True)\n",
    "encoded = one_hot.fit_transform(full_df[\"vesselType\"])\n",
    "\n",
    "full_df[encoded_cols] = encoded[encoded_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add lag features for key metrics\n",
    "lag_cols = [\"prev_lat\", \"prev_lng\", \"prev_distance\", \"prev_fwd_azimuth\", \"time_diff\"]\n",
    "for col in lag_cols:\n",
    "    # Add lags\n",
    "    for lag in [1, 2, 3, 4]:\n",
    "        full_df[f\"{col}_lag{lag}\"] = full_df.groupby(\"vesselId\")[col].shift(lag)\n",
    "\n",
    "    # Add rolling means\n",
    "    for window in [4, 12, 24]:\n",
    "        full_df[f\"{col}_rolling_mean_{window}\"] = (\n",
    "            full_df.groupby(\"vesselId\")[col]\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .mean()\n",
    "            .reset_index(0, drop=True)\n",
    "        )\n",
    "\n",
    "for window in [4, 12, 24]:\n",
    "    full_df[f\"prev_distance_rolling_sum_{window}\"] = (\n",
    "        full_df.groupby(\"vesselId\")[\"prev_distance\"]\n",
    "        .rolling(window=window, min_periods=1)\n",
    "        .sum()\n",
    "        .reset_index(0, drop=True)\n",
    "    )\n",
    "\n",
    "# Add the new columns to features list\n",
    "lag_rolling_cols = [\n",
    "    f\"{col}_{transform}\"\n",
    "    for col in lag_cols\n",
    "    for transform in (\n",
    "        [f\"lag{i}\" for i in range(1, 5)] + [f\"rolling_mean_{w}\" for w in [4, 12, 24]]\n",
    "    )\n",
    "] + [f\"prev_distance_rolling_sum_{w}\" for w in [4, 12, 24]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_circular_features(df, lat_col, long_col, azimuth_col):\n",
    "    # Convert degrees to radians\n",
    "    df[\"lat_rad\"] = np.deg2rad(df[lat_col])\n",
    "    df[\"lon_rad\"] = np.deg2rad(df[long_col])\n",
    "    df[\"azimuth_rad\"] = np.deg2rad(df[azimuth_col])\n",
    "\n",
    "    # Sine and Cosine transformations\n",
    "    df[\"sin_lat\"] = np.sin(df[\"lat_rad\"])\n",
    "    df[\"cos_lat\"] = np.cos(df[\"lat_rad\"])\n",
    "    df[\"sin_lon\"] = np.sin(df[\"lon_rad\"])\n",
    "    df[\"cos_lon\"] = np.cos(df[\"lon_rad\"])\n",
    "    df[\"sin_azimuth\"] = np.sin(df[\"azimuth_rad\"])\n",
    "    df[\"cos_azimuth\"] = np.cos(df[\"azimuth_rad\"])\n",
    "    cols = [\"sin_lat\", \"cos_lat\", \"sin_lon\", \"cos_lon\", \"cos_azimuth\", \"sin_azimuth\"]\n",
    "\n",
    "    return df, cols\n",
    "\n",
    "\n",
    "full_df, circular_cols = add_circular_features(\n",
    "    full_df, \"prev_lat\", \"prev_lng\", \"prev_fwd_azimuth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = (\n",
    "    [\n",
    "        \"time_diff\",\n",
    "        \"prev_lat\",\n",
    "        \"prev_lng\",\n",
    "        \"prev_sog\",\n",
    "        \"prev_distance\",\n",
    "        \"prev_fwd_azimuth\",\n",
    "        \"CEU\",\n",
    "        \"DWT\",\n",
    "        \"GT\",\n",
    "        \"breadth\",\n",
    "        \"length\",\n",
    "        \"yearBuilt\",\n",
    "        \"dist_to_port\",\n",
    "        \"latitude_port\",\n",
    "        \"longitude_port\",\n",
    "    ]\n",
    "    + time_cols\n",
    "    + encoded_cols\n",
    "    + lag_rolling_cols\n",
    "    + cluster_cols\n",
    "    + vessel_stats_cols\n",
    "    + circular_cols\n",
    "    + [\n",
    "        \"closest_port_count\",\n",
    "        \"shipping_line_count\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "targets = [\"distance\", \"fwd_azimuth\", \"latitude\", \"longitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = full_df[\"ID\"] == -1\n",
    "# val_df = full_df[(full_df[\"time\"] > val_cutoff) & (full_df[\"time\"] < test_start)]\n",
    "train_df = full_df[full_df[\"time\"] < test_start]\n",
    "test_df = full_df[full_df[\"time\"] >= test_start]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiOutputRegressor(\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=xgb.XGBRegressor(max_depth=12, n_estimators=100, random_state=42),\n",
    "        func=np.deg2rad,\n",
    "        inverse_func=np.rad2deg,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MultiOutputRegressor(\n",
    "#     StackingRegressor(\n",
    "#         estimators=[\n",
    "#             (\n",
    "#                 \"xgb\",\n",
    "#                 xgb.XGBRegressor(\n",
    "#                     alpha=0.05, max_depth=12, n_estimators=100, random_state=123\n",
    "#                 ),\n",
    "#             ),\n",
    "#             (\n",
    "#                 \"hgb\",\n",
    "#                 HistGradientBoostingRegressor(\n",
    "#                     max_depth=12, max_iter=100, random_state=123\n",
    "#                 ),\n",
    "#             ),\n",
    "#             (\"lgb\", LGBMRegressor(max_depth=12, n_estimators=100, random_state=123)),\n",
    "#             (\n",
    "#                 \"cat\",\n",
    "#                 CatBoostRegressor(\n",
    "#                     max_depth=12, n_estimators=100, random_seed=123, verbose=False\n",
    "#                 ),\n",
    "#             ),\n",
    "#         ],\n",
    "#         final_estimator=xgb.XGBRegressor(\n",
    "#             max_depth=6, n_estimators=50, random_state=123\n",
    "#         ),\n",
    "#         passthrough=True,\n",
    "#         cv=2,\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(train_df[features], train_df[targets][[\"latitude\", \"longitude\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions autoregressively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_port_for_row(row, longitude_col, latitude_col):\n",
    "\n",
    "    df_row = pd.DataFrame([row])\n",
    "    row_gdf = df_to_gdf(\n",
    "        df_row, longitude_col=longitude_col, latitude_col=latitude_col\n",
    "    ).to_crs(epsg=\"3857\")\n",
    "\n",
    "    row_with_nearest_port = row_gdf.sjoin_nearest(\n",
    "        ports_gdf, how=\"left\", distance_col=\"dist_to_port\"\n",
    "    )\n",
    "\n",
    "    # Extract the closest port info\n",
    "    closest_port = row_with_nearest_port[\"closest_port\"].values[0]\n",
    "    dist_to_port = row_with_nearest_port[\"dist_to_port\"].values[0]\n",
    "    latitude_port = row_with_nearest_port[\"latitude_port\"].values[0]\n",
    "    longitude_port = row_with_nearest_port[\"longitude_port\"].values[0]\n",
    "\n",
    "    return closest_port, dist_to_port, latitude_port, longitude_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60242 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'find_closest_port_for_row' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m distance \u001b[38;5;241m=\u001b[39m distance \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1.852\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m     26\u001b[0m sog \u001b[38;5;241m=\u001b[39m distance \u001b[38;5;241m/\u001b[39m (row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_diff\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3600\u001b[39m)\n\u001b[1;32m     27\u001b[0m closest_port, dist_to_port, latitude_port, longitude_port \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 28\u001b[0m     \u001b[43mfind_closest_port_for_row\u001b[49m(\n\u001b[1;32m     29\u001b[0m         row[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprev_lat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprev_lng\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[1;32m     30\u001b[0m         latitude_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprev_lat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     31\u001b[0m         longitude_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprev_lng\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m closest_port_count \u001b[38;5;241m=\u001b[39m count_ports_encoder\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m     35\u001b[0m     closest_port\n\u001b[1;32m     36\u001b[0m )\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'find_closest_port_for_row' is not defined"
     ]
    }
   ],
   "source": [
    "def time_series_prediction(test_df: pd.DataFrame):\n",
    "    lng_pred = []\n",
    "    lat_pred = []\n",
    "    total_steps = test_df.shape[0]\n",
    "\n",
    "    with tqdm(total=total_steps) as progress_bar:\n",
    "        for vesselId in test_df[\"vesselId\"].unique():\n",
    "            vessel_rows = test_df[test_df[\"vesselId\"] == vesselId].copy()\n",
    "\n",
    "            steps = vessel_rows.shape[0]\n",
    "            vessel_rows[\"step\"] = np.arange(steps)\n",
    "\n",
    "            for i in range(steps):\n",
    "                row = vessel_rows.loc[vessel_rows[\"step\"] == i]\n",
    "                latitude = model.predict(row[features])[:, 0].item()\n",
    "                longitude = model.predict(row[features])[:, 1].item()\n",
    "                lng_pred.append(longitude)\n",
    "                lat_pred.append(latitude)\n",
    "\n",
    "                fwd_azimuth, back_azimuth, distance = geodesic.inv(\n",
    "                    row[\"prev_lng\"].item(),\n",
    "                    row[\"prev_lat\"].item(),\n",
    "                    longitude,\n",
    "                    latitude,\n",
    "                )\n",
    "                distance = distance / (1.852 * 1000)\n",
    "                sog = distance / (row[\"time_diff\"].item() / 3600)\n",
    "                closest_port, dist_to_port, latitude_port, longitude_port = (\n",
    "                    find_closest_port_for_row(\n",
    "                        row[[\"prev_lat\", \"prev_lng\"]],\n",
    "                        latitude_col=\"prev_lat\",\n",
    "                        longitude_col=\"prev_lng\",\n",
    "                    )\n",
    "                )\n",
    "                closest_port_count = count_ports_encoder.transform(\n",
    "                    closest_port\n",
    "                ).values.item()\n",
    "\n",
    "                if i < steps - 1:\n",
    "                    vessel_rows.loc[\n",
    "                        vessel_rows[\"step\"] == i + 1,\n",
    "                        [\n",
    "                            \"prev_distance\",\n",
    "                            \"prev_fwd_azimuth\",\n",
    "                            \"prev_lat\",\n",
    "                            \"prev_lng\",\n",
    "                            \"cos_lat\",\n",
    "                            \"sin_lat\",\n",
    "                            \"cos_lon\",\n",
    "                            \"sin_lon\",\n",
    "                            \"cos_azimuth\",\n",
    "                            \"sin_azimuth\",\n",
    "                            \"prev_sog\",\n",
    "                            \"closest_port_count\",\n",
    "                            \"dist_to_port\",\n",
    "                            \"latitude_port\",\n",
    "                            \"longitude_port\",\n",
    "                        ],\n",
    "                    ] = [\n",
    "                        distance,\n",
    "                        fwd_azimuth,\n",
    "                        latitude,\n",
    "                        longitude,\n",
    "                        np.cos(latitude),\n",
    "                        np.sin(latitude),\n",
    "                        np.cos(longitude),\n",
    "                        np.sin(longitude),\n",
    "                        np.cos(fwd_azimuth),\n",
    "                        np.sin(fwd_azimuth),\n",
    "                        sog,\n",
    "                        closest_port_count,\n",
    "                        dist_to_port.item(),\n",
    "                        latitude_port.item(),\n",
    "                        longitude_port.item(),\n",
    "                    ]\n",
    "\n",
    "                    for col in [col for col in lag_cols if col != \"time_diff\"]:\n",
    "                        vessel_rows.loc[vessel_rows[\"step\"] == i + 1, f\"{col}_lag1\"] = (\n",
    "                            vessel_rows.loc[vessel_rows[\"step\"] == i, col].item()\n",
    "                        )\n",
    "                        for lag in range(2, 5):\n",
    "                            vessel_rows.loc[\n",
    "                                vessel_rows[\"step\"] == i + 1, f\"{col}_lag{lag}\"\n",
    "                            ] = vessel_rows.loc[\n",
    "                                vessel_rows[\"step\"] == i, f\"{col}_lag{lag-1}\"\n",
    "                            ].item()\n",
    "\n",
    "                        for window in [4, 12, 24]:\n",
    "                            vessel_rows.loc[\n",
    "                                vessel_rows[\"step\"] == i + 1,\n",
    "                                f\"{col}_rolling_mean_{window}\",\n",
    "                            ] = (\n",
    "                                vessel_rows.loc[vessel_rows[\"step\"] <= i + 1, col]\n",
    "                                .tail(window)\n",
    "                                .mean()\n",
    "                            )\n",
    "\n",
    "                    for window in [4, 12, 24]:\n",
    "                        vessel_rows.loc[\n",
    "                            vessel_rows[\"step\"] == i + 1,\n",
    "                            f\"prev_distance_rolling_sum_{window}\",\n",
    "                        ] = (\n",
    "                            vessel_rows.loc[\n",
    "                                vessel_rows[\"step\"] <= i + 1, \"prev_distance\"\n",
    "                            ]\n",
    "                            .tail(window)\n",
    "                            .sum()\n",
    "                        )\n",
    "\n",
    "                progress_bar.update()\n",
    "\n",
    "    return lat_pred, lng_pred\n",
    "\n",
    "\n",
    "lat_pred, lng_pred = time_series_prediction(test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
